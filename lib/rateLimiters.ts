import { NextRequest } from 'next/server'
import { LRUCache } from 'lru-cache'
import { RATE_LIMIT } from './constants'
import { ApiError } from './errors'

// ========================================================================
// SISTEMA DE RATE LIMITING PARA PROTEGER NUESTRAS APIs
// ========================================================================
// Este m√≥dulo previene que los usuarios hagan demasiadas peticiones
// y protejan nuestros recursos (servidor, APIs externas como OpenAI, etc.)

/**
 * Cache LRU (Least Recently Used) para almacenar contadores de peticiones por IP
 * 
 * ¬øPor qu√© LRU? 
 * - Autom√°ticamente elimina las IPs m√°s antiguas cuando se llena
 * - Mantiene en memoria solo las IPs m√°s activas
 * - Evita consumo excesivo de memoria
 * 
 * Estructura del cache: 
 * {
 *   "192.168.1.1": 5,  // Esta IP ha hecho 5 peticiones
 *   "10.0.0.1": 2,     // Esta IP ha hecho 2 peticiones
 * }
 */
const rateLimitCache = new LRUCache<string, number>({
  max: RATE_LIMIT.CACHE_MAX_SIZE,  // M√°ximo n√∫mero de IPs que recordamos
  ttl: RATE_LIMIT.CACHE_TTL_MS     // Tiempo de vida: despu√©s de este tiempo, el contador se resetea autom√°ticamente
})

/**
 * Funci√≥n principal de rate limiting
 * 
 * ¬øC√≥mo funciona?
 * 1. Identifica al usuario por su IP
 * 2. Cuenta cu√°ntas peticiones ha hecho en el per√≠odo actual
 * 3. Si excede el l√≠mite -> ERROR 429
 * 4. Si no -> incrementa contador y permite continuar
 * 
 * @param req - Request de Next.js con headers y metadata
 * @throws ApiError(429) si se excede el l√≠mite de peticiones
 */
export const rateLimiter = async (req: NextRequest) => {
  // ========================================================================
  // PASO 1: IDENTIFICAR AL USUARIO
  // ========================================================================
  
  /**
   * Obtener la IP real del usuario
   * 
   * ¬øPor qu√© 'x-forwarded-for'?
   * - Cuando usas Vercel, Cloudflare, o cualquier proxy/load balancer
   * - La IP real est√° en este header, no en req.ip
   * - Sin esto, todas las peticiones aparecer√≠an como la IP del servidor
   * 
   * Fallback '127.0.0.1':
   * - Para desarrollo local donde no hay proxy
   * - Evita que el c√≥digo falle si no encuentra IP
   */
  const ip = req.headers.get('x-forwarded-for') || '127.0.0.1'
  
  // ========================================================================
  // PASO 2: VERIFICAR L√çMITES
  // ========================================================================
  
  // L√≠mite configurado en constants.ts (ej: 10 peticiones por minuto)
  const limit = RATE_LIMIT.REQUESTS_PER_MINUTE
  
  /**
   * Obtener contador actual para esta IP
   * 
   * rateLimitCache.get(ip) puede retornar:
   * - undefined (primera vez que vemos esta IP)
   * - number (n√∫mero de peticiones anteriores)
   * 
   * || 0 convierte undefined a 0
   * as number es para TypeScript (sabemos que ser√° un n√∫mero)
   */
  const currentCount = (rateLimitCache.get(ip) || 0) as number
  
  // ========================================================================
  // PASO 3: DECIDIR SI BLOQUEAR O PERMITIR
  // ========================================================================
  
  if (currentCount >= limit) {
    /**
     * ¬°L√çMITE EXCEDIDO! - Bloquear petici√≥n
     * 
     * Error 429: "Too Many Requests" - Est√°ndar HTTP
     * 
     * Informaci√≥n adicional √∫til:
     * - limitResetTime: Cu√°ndo podr√° hacer peticiones de nuevo
     * - Ayuda al cliente a saber cu√°ndo reintentar
     */
    throw new ApiError(
      429,
      'Rate limit exceeded. Please try again later.',
      { 
        limitResetTime: new Date(Date.now() + RATE_LIMIT.CACHE_TTL_MS).toISOString()
      }
    )
  }
  
  /**
   * TODO OK - Permitir petici√≥n e incrementar contador
   * 
   * Guardamos currentCount + 1 en el cache
   * El TTL (tiempo de vida) se resetea autom√°ticamente
   * 
   * Ejemplo:
   * - Primera petici√≥n: currentCount = 0, guardamos 1
   * - Segunda petici√≥n: currentCount = 1, guardamos 2
   * - etc...
   */
  rateLimitCache.set(ip, currentCount + 1)
  
  // Si llegamos aqu√≠, la petici√≥n est√° permitida ‚úÖ
  // La funci√≥n termina sin error = petici√≥n puede continuar
}

// ========================================================================
// NOTAS PARA EL FUTURO:
// ========================================================================
// 
// üîß CONFIGURACI√ìN:
// - Ajusta RATE_LIMIT.REQUESTS_PER_MINUTE seg√∫n tus necesidades
// - APIs costosas (OpenAI) = l√≠mite bajo (5-10/min)
// - APIs simples = l√≠mite alto (100/min)
//
// üöÄ PRODUCCI√ìN:
// - Considera usar Redis en lugar de memoria para m√∫ltiples servidores
// - Monitorea m√©tricas: cu√°ntas peticiones se bloquean
//
// üõ°Ô∏è SEGURIDAD:
// - Este sistema previene ataques de fuerza bruta simples
// - Para ataques sofisticados, considera Cloudflare o similar
//
// üêõ DEBUG:
// - Si los l√≠mites parecen no funcionar, verifica que el IP se obtiene bien
// - En desarrollo local, todas las peticiones vendr√°n de 127.0.0.1